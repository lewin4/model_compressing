dataloader:
#  imagenet_path: <your_imagenet_path_here>
#  imagenet_path: D:\Code\data\cifar-100
#  imagenet_path: E:\LY\data\cat_vs_dog\train
  img_dir: D:\Code\data\sewage\small_dataset\small_img
  mask_dir: D:\Code\data\sewage\small_dataset\small_label
  num_workers: 8
  batch_size: 4
  train_shuffle: True
  validation_shuffle: False
  pin_memory: True
  img_shape:
    - 768
    - 1024

# training hyperparams
epochs: 2
learning_rate: 0.0001
momentum: 0.9
weight_decay: 0.00001 # 1e-4

optimizer: adam # must be either sgd or adam

# lr scheduling
lr_scheduler:
  type: cosine
  min_lr: 1.e-6

skip_initial_validation: True
output_path: ../output/hrnet

# model architecture
model:
  arch: custom
  model_path: D:\Code\HRNet-Semantic-Segmentation\tools\output\sewage\seg_hrnet_ocr_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484\best_model.pth

  compression_parameters:
    ignored_modules:
      # list of layer names that you do not want to compress.
      # We follow Stock et al. "And the bit goes down: revisiting the quantization of deep neural networks", ICLR 2020
      # and do not compress the first 7x7 convolutional layer, as it represents only 0.1-0.05% of the network weights
      - encoder.enc_blocks.0.conv1

    k: 256
    fc_subvector_size: 4 # d_fc
    pw_subvector_size: 4 # d_pw
    # Small or large block compression regime for convolutional layers
    large_subvectors: False
    k_means_type: src # kmeans, kmedians, src, slow_src
    k_means_n_iters: 10

    # Used to overwrite configs
    layer_specs:
      fc:
        k: 2048 # Same as BGD
        k_means_type: src

  use_permutations: True
  sls_iterations: 10_000     #test哈哈哈

  permutations:   # parent-children relationships for permutation optimization
    -
      - parents: [encoder.enc_blocks.0.conv1]
      - children: [encoder.enc_blocks.0.conv2]
    -
      - parents: [encoder.enc_blocks.0.conv2, decoder.upconvs.3]
      - children: [encoder.enc_blocks.1.conv1, decoder.dec_blocks.3.conv1]
    -
      - parents: [encoder.enc_blocks.1.conv1]
      - children: [encoder.enc_blocks.1.conv2]
    -
      - parents: [encoder.enc_blocks.1.conv2, decoder.upconvs.2]
      - children: [encoder.enc_blocks.2.conv1, decoder.dec_blocks.2.conv1]
    -
      - parents: [encoder.enc_blocks.2.conv1]
      - children: [encoder.enc_blocks.2.conv2]
    -
      - parents: [encoder.enc_blocks.2.conv2, decoder.upconvs.1]
      - children: [encoder.enc_blocks.3.conv1, decoder.dec_blocks.1.conv1]
    -
      - parents: [encoder.enc_blocks.3.conv1]
      - children: [encoder.enc_blocks.3.conv2]
    -
      - parents: [encoder.enc_blocks.3.conv2, decoder.upconvs.0]
      - children: [encoder.enc_blocks.4.conv1, decoder.dec_blocks.0.conv1]
    -
      - parents: [encoder.enc_blocks.4.conv1]
      - children: [encoder.enc_blocks.4.conv2]
    -
      - parents: [encoder.enc_blocks.4.conv2]
      - children: [decoder.upconvs.0]
    -
      - parents: [decoder.dec_blocks.0.conv1]
      - children: [decoder.dec_blocks.0.conv2]
    -
      - parents: [decoder.dec_blocks.0.conv2]
      - children: [decoder.upconvs.1]
    -
      - parents: [decoder.dec_blocks.1.conv1]
      - children: [decoder.dec_blocks.1.conv2]
    -
      - parents: [decoder.dec_blocks.1.conv2]
      - children: [decoder.upconvs.2]
    -
      - parents: [decoder.dec_blocks.2.conv1]
      - children: [decoder.dec_blocks.2.conv2]
    -
      - parents: [decoder.dec_blocks.2.conv2]
      - children: [decoder.upconvs.3]
    -
      - parents: [decoder.dec_blocks.3.conv1]
      - children: [decoder.dec_blocks.3.conv2]
    -
      - parents: [decoder.dec_blocks.3.conv2]
      - children: [head]